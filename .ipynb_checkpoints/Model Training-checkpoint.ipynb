{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir_path = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "max_min = 40 #min\n",
    "min_min = 5 #min\n",
    "n_files = max_min-min_min+1\n",
    "data = {}\n",
    "\n",
    "for i in range(n_files):\n",
    "    data[\"data_\"+str(5+i)+\"min\"] = pd.read_csv(os.path.join(dir_path, \"match_summary_\"+str(5+i)+\"min.csv\"), \n",
    "                                               dtype=int, \n",
    "                                               index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another notebook we have determined that a support vector machine classifier seems to work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_random(X, y, test_ratio=0.1, random_seed=42):\n",
    "    np.random.seed(seed=random_seed)\n",
    "    shuffled_indices = np.random.permutation(len(X))\n",
    "    test_num = int(np.round(test_ratio*len(X)))\n",
    "    X_test = X[shuffled_indices[:test_num]]\n",
    "    y_test = y[shuffled_indices[:test_num]]\n",
    "    X_train = X[shuffled_indices[test_num:]]\n",
    "    y_train = y[shuffled_indices[test_num:]]\n",
    "    \n",
    "    return X_test, y_test, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 16 of 40 min."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "import sys\n",
    "\n",
    "svc=SVC(gamma=\"scale\", kernel=\"linear\", C=10.0)\n",
    "\n",
    "classifiers = []\n",
    "accuracy = []\n",
    "\n",
    "for (i, key) in enumerate(data):\n",
    "    sys.stdout.write(\"\\rProcessing: \" + str(i + 5) + \" of 40 min.\")\n",
    "    sys.stdout.flush()\n",
    "    dat = data[key]\n",
    "    y = np.array(dat[\"blueWin\"])\n",
    "    X = dat.drop(\"blueWin\", axis=1).values\n",
    "    X_test, y_test, X_train, y_train = train_test_split_random(X, y)\n",
    "    svc_clone = clone(svc)\n",
    "    svc_clone.fit(X_train, y_train)\n",
    "    y_pred = svc_clone.predict(X_test)\n",
    "    \n",
    "    classifiers.append((i+5, svc_clone))\n",
    "    accuracy.append((i+5, np.round(np.mean(y_pred==y_test)*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LetÂ´s check the accuracy of the models at different minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 50.0), (6, 63.27), (7, 62.24)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "ax.set_title(\"Distribution of game lengths based on dataset size\", fontsize =20)\n",
    "\n",
    "ax.plot([time for (time, acc) in accuracy], \n",
    "        [acc for (time, acc) in accuracy], \n",
    "        marker='o', linestyle='dashed', linewidth=2, markersize=8)\n",
    "\n",
    "ax.set_xticklabels([0, 5, 10, 15, 20, 25, 30, 35, 40, 45], fontsize=14)\n",
    "ax.set_xlim(0, 45)\n",
    "ax.set_ylim(0, 110)\n",
    "ax.set_yticklabels([0, 20, 40, 60, 80, 100], fontsize=14)\n",
    "ax.set_xlabel(\"Game length [min]\", fontsize=18)\n",
    "ax.set_ylabel(\"Accuracy [%]\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(data[\"data_5min\"].keys())[1:]\n",
    "coeffs = [clf.coef_ for (time, clf) in classifiers]\n",
    "\n",
    "coefficients = {key: [] for key in features}\n",
    "for array in coeffs:\n",
    "    for (i, key) in enumerate(features):\n",
    "        coefficients[key].append(array[i])\n",
    "\n",
    "n_rows = 8\n",
    "n_columns = 4\n",
    "x_axis = [i+5 for i in range(n_files)]\n",
    "corr_index = np.array([i for i in range(n_rows*n_columns)]).reshape((n_rows, -1))\n",
    "\n",
    "fig, ax = plt.subplots(n_rows, n_columns, figsize=(20,35))\n",
    " \n",
    "for k in range(n_rows):\n",
    "    for l in range(n_columns):\n",
    "        try:\n",
    "            feature = features[corr_index[k, l]]\n",
    "            ax[k, l].set_title(feature, fontsize=18)\n",
    "            ax[k, l].plot(x_axis, correlations[feature], linestyle='-', linewidth=2)\n",
    "            ax[k, l].set_xlim(0, 42.5)\n",
    "            ax[k, l].set_xticklabels([0, 5, 10, 15, 20, 25, 30, 35, 40], fontsize=14)\n",
    "            ax[k, l].set_ylim(-1, 1)\n",
    "        except:\n",
    "            pass\n",
    "plt.tight_layout()      \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
